{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "19bad499-5a97-425c-beec-dcd88d693d4c",
   "metadata": {},
   "source": [
    "# Examples\n",
    "The `pympipool.Executor` extends the interface of the [`concurrent.futures.Executor`](https://docs.python.org/3/library/concurrent.futures.html#module-concurrent.futures)\n",
    "to simplify the up-scaling of individual functions in a given workflow."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f752ec8d-50b8-46fb-86f2-08a9126f1a39",
   "metadata": {},
   "source": [
    "## Compatibility\n",
    "Starting with the basic example of `1+1=2`. With the `ThreadPoolExecutor` from the [`concurrent.futures`](https://docs.python.org/3/library/concurrent.futures.html#module-concurrent.futures)\n",
    "standard library this can be written as: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "584cd590-acaf-48d7-a5b5-e4049a9626b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from concurrent.futures import ThreadPoolExecutor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "73673e42-2c68-4b91-b6ff-db1ecb2c0587",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2\n"
     ]
    }
   ],
   "source": [
    "with ThreadPoolExecutor(\n",
    "    max_workers=1,\n",
    ") as exe:\n",
    "    future = exe.submit(sum, [1, 1])\n",
    "    print(future.result())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32156314-02a9-4210-8a8c-94afe09b64f6",
   "metadata": {},
   "source": [
    "In this case `max_workers=1` limits the number of threads uses by the `ThreadPoolExecutor` to one. Then the `sum()` \n",
    "function is submitted to the executor with a list with two ones `[1, 1]` as input. A [`concurrent.futures.Future`](https://docs.python.org/3/library/concurrent.futures.html#module-concurrent.futures)\n",
    "object is returned. The `Future` object allows to check the status of the execution with the `done()` method which \n",
    "returns `True` or `False` depending on the state of the execution. Or the main process can wait until the execution is \n",
    "completed by calling `result()`. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b750d830-bd0d-4474-9f70-913d0b9d6b8a",
   "metadata": {},
   "source": [
    "The result of the calculation is `1+1=2`. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4fbf72a2-0e0e-43ce-be8f-db3489c4eafe",
   "metadata": {},
   "source": [
    "The `pympipool.Executor` class extends the interface of the [`concurrent.futures.Executor`](https://docs.python.org/3/library/concurrent.futures.html#module-concurrent.futures) \n",
    "class by providing more parameters to specify the level of parallelism. In addition, to specifying the maximum number \n",
    "of workers `max_workers` the user can also specify the number of cores per worker `cores_per_worker` for MPI based \n",
    "parallelism, the number of threads per core `threads_per_core` for thread based parallelism and the number of GPUs per\n",
    "worker `gpus_per_worker`. Finally, for those backends which support over-subscribing this can also be enabled using the \n",
    "`oversubscribe` parameter. All these parameters are optional, so the `pympipool.Executor` can be used as a drop-in \n",
    "replacement for the [`concurrent.futures.Executor`](https://docs.python.org/3/library/concurrent.futures.html#module-concurrent.futures)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b5a26e2-3d18-4778-ba10-e3e213b70433",
   "metadata": {},
   "source": [
    "The previous example is rewritten for the `pympipool.Executor`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "60373c38-63f8-48dc-be0f-ddb71ebf88f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pympipool import Executor "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "fd755b28-ff01-4530-9099-001cac151e31",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2\n"
     ]
    }
   ],
   "source": [
    "with Executor(\n",
    "    max_workers=1, \n",
    "    cores_per_worker=1, \n",
    "    threads_per_core=1, \n",
    "    gpus_per_worker=0, \n",
    "    oversubscribe=False\n",
    ") as exe:\n",
    "    future = exe.submit(sum, [1,1])\n",
    "    print(future.result())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44c4bc4b-cf97-461e-98e7-62bcdb8caff2",
   "metadata": {},
   "source": [
    "The result of the calculation is again `1+1=2`."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "331aed93-806a-4057-ab9c-19479190f472",
   "metadata": {},
   "source": [
    "Beyond pre-defined functions like the `sum()` function, the same functionality can be used to submit user-defined \n",
    "functions. In the following example a custom summation function is defined: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "cdeb8710-b328-463d-a436-82d6756e76b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc(*args):\n",
    "    return sum(*args)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d5efa995-d4d4-4f9c-a7e6-38dd66143535",
   "metadata": {},
   "source": [
    "In contrast to the previous example where just a single function was submitted to a single worker, in this case a total\n",
    "of four functions is submitted to a group of two workers `max_workers=2`. Consequently, the functions are executed as a\n",
    "set of two pairs. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "82033832-7ccd-4c67-a1fb-57f55710b77c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3, 4, 5, 6]\n"
     ]
    }
   ],
   "source": [
    "with Executor(max_workers=2) as exe:\n",
    "    fs_1 = exe.submit(calc, [2, 1])\n",
    "    fs_2 = exe.submit(calc, [2, 2])\n",
    "    fs_3 = exe.submit(calc, [2, 3])\n",
    "    fs_4 = exe.submit(calc, [2, 4])\n",
    "    print([\n",
    "        fs_1.result(), \n",
    "        fs_2.result(), \n",
    "        fs_3.result(), \n",
    "        fs_4.result(),\n",
    "    ])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86838528-312e-46cc-b022-0c946bf95037",
   "metadata": {},
   "source": [
    "The snippet can be executed with any python interpreter. It returns the corresponding sums as expected. The same can be achieved with the built-in [`concurrent.futures.Executor`](https://docs.python.org/3/library/concurrent.futures.html#module-concurrent.futures)\n",
    "classes. Still one advantage of using the `pympipool.Executor` rather than the built-in ones, is the ability to execute \n",
    "the same commands in interactive environments like [Jupyter notebooks](https://jupyter.org). This is achieved by using \n",
    "[cloudpickle](https://github.com/cloudpipe/cloudpickle) to serialize the python function and its parameters rather than\n",
    "the regular pickle package. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4de690ed-661c-4e6e-a97e-c478393d0dc6",
   "metadata": {},
   "source": [
    "For backwards compatibility with the [`multiprocessing.Pool`](https://docs.python.org/3/library/multiprocessing.html) \n",
    "class the [`concurrent.futures.Executor`](https://docs.python.org/3/library/concurrent.futures.html#module-concurrent.futures)\n",
    "also implements the `map()` function to map a series of inputs to a function. The same `map()` function is also \n",
    "available in the `pympipool.Executor`: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "3f06b0c1-5ee1-40c5-82ab-31d77cfcdb46",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3, 4, 5, 6]\n"
     ]
    }
   ],
   "source": [
    "with Executor(max_workers=2) as exe:\n",
    "    print(list(exe.map(calc, [[2, 1], [2, 2], [2, 3], [2, 4]])))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5d0f249-23bb-4727-8b09-87320ecb98eb",
   "metadata": {},
   "source": [
    "The results remain the same. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "580b00ee-6d5b-4ca9-ba36-ff70128c0b6b",
   "metadata": {},
   "source": [
    "## Data Handling\n",
    "A limitation of many parallel approaches is the overhead in communication when working with large datasets. Instead of\n",
    "reading the same dataset repetitively, the `pympipool.Executor` loads the dataset only once per worker and afterwards \n",
    "each function submitted to this worker has access to the dataset, as it is already loaded in memory. To achieve this\n",
    "the user defines an initialization function `init_function` which returns a dictionary with one key per dataset. The \n",
    "keys of the dictionary can then be used as additional input parameters in each function submitted to the `pympipool.Executor`.\n",
    "This functionality is illustrated in the following example: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "8fe8c750-4dc5-4b26-ad8d-9f755bff3494",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc(i, j, k):\n",
    "    return i + j + k"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "5f943266-1bee-421e-a1b4-583d222b1c99",
   "metadata": {},
   "outputs": [],
   "source": [
    "def init_function():\n",
    "    return {\"j\": 4, \"k\": 3, \"l\": 2}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "0debe907-b646-4fd5-bae7-46b16645d2f3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10\n"
     ]
    }
   ],
   "source": [
    "with Executor(max_workers=1, init_function=init_function) as exe:\n",
    "    fs = exe.submit(calc, 2, j=5)\n",
    "    print(fs.result())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72fa803a-ace0-41ea-8090-d64dfd0797cc",
   "metadata": {},
   "source": [
    "The function `calc()` requires three inputs `i`, `j` and `k`. But when the function is submitted to the executor only \n",
    "two inputs are provided `fs = exe.submit(calc, 2, j=5)`. In this case the first input parameter is mapped to `i=2`, the\n",
    "second input parameter is specified explicitly `j=5` but the third input parameter `k` is not provided. So the \n",
    "`pympipool.Executor` automatically checks the keys set in the `init_function()` function. In this case the returned \n",
    "dictionary `{\"j\": 4, \"k\": 3, \"l\": 2}` defines `j=4`, `k=3` and `l=2`. For this specific call of the `calc()` function,\n",
    "`i` and `j` are already provided so `j` is not required, but `k=3` is used from the `init_function()` and as the `calc()`\n",
    "function does not define the `l` parameter this one is also ignored. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1443d216-1add-445a-a662-5b16af6c1443",
   "metadata": {},
   "source": [
    "The result is `2+5+3=10` as `i=2` and `j=5` are provided during the submission and `k=3` is defined in the `init_function()`\n",
    "function."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d1e21ec-0b8d-45bf-bfb1-62b3df8e242a",
   "metadata": {},
   "source": [
    "## Up-Scaling \n",
    "The availability of certain features depends on the backend `pympipool` is installed with. In particular the thread \n",
    "based parallelism and the GPU assignment is only available with the `pympipool.slurm.PySlurmExecutor` or the \n",
    "`pympipool.flux.PyFluxExecutor` backend. The latter is recommended based on the easy installation, the faster allocation \n",
    "of resources as the resources are managed within the allocation and no central databases is used and the superior level \n",
    "of fine-grained resource assignment which is typically not available on other HPC resource schedulers including the\n",
    "[SLURM workload manager](https://www.schedmd.com). The `pympipool.flux.PyFluxExecutor` requires \n",
    "[flux framework](https://flux-framework.org) to be installed in addition to the `pympipool` package. The features are \n",
    "summarized in the table below: \n",
    "\n",
    "|     Feature \\ Backend      | `PyMpiExecutor` | `PySlurmExecutor` | `PyFluxExecutor` |\n",
    "|:--------------------------:|:---------------:|:-----------------:|:----------------:|\n",
    "|  Thread based parallelism  |       no        |        yes        |       yes        | \n",
    "|   MPI based parallelism    |       yes       |        yes        |       yes        |\n",
    "|       GPU assignment       |       no        |        yes        |       yes        |\n",
    "| Resource over-subscription |       yes       |        yes        |        no        |\n",
    "|        Scalability         |     1 node      |    ~100 nodes     |     no limit     |"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3b9cc80-70ed-4bc8-abf9-62ecbd70b960",
   "metadata": {},
   "source": [
    "### Thread-based Parallelism\n",
    "The number of threads per core can be controlled with the `threads_per_core` parameter during the initialization of the \n",
    "`pympipool.Executor`. Unfortunately, there is no uniform way to control the number of cores a given underlying library \n",
    "uses for thread based parallelism, so it might be necessary to set certain environment variables manually: \n",
    "\n",
    "* `OMP_NUM_THREADS`: for openmp\n",
    "* `OPENBLAS_NUM_THREADS`: for openblas\n",
    "* `MKL_NUM_THREADS`: for mkl\n",
    "* `VECLIB_MAXIMUM_THREADS`: for accelerate on Mac Os X\n",
    "* `NUMEXPR_NUM_THREADS`: for numexpr\n",
    "\n",
    "At the current stage `pympipool.Executor` does not set these parameters itself, so you have to add them in the function\n",
    "you submit before importing the corresponding library: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "fbf5f7b2-eb3e-4a81-bae8-e429747300a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc(i):\n",
    "    import os\n",
    "    os.environ[\"OMP_NUM_THREADS\"] = \"2\"\n",
    "    os.environ[\"OPENBLAS_NUM_THREADS\"] = \"2\"\n",
    "    os.environ[\"MKL_NUM_THREADS\"] = \"2\"\n",
    "    os.environ[\"VECLIB_MAXIMUM_THREADS\"] = \"2\"\n",
    "    os.environ[\"NUMEXPR_NUM_THREADS\"] = \"2\"\n",
    "    import numpy as np\n",
    "    return i"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "334619d0-8d95-419e-885c-e5bc05747584",
   "metadata": {},
   "source": [
    "Most modern CPUs use hyper-threading to present the operating system with double the number of virtual cores compared to\n",
    "the number of physical cores available. So unless this functionality is disabled `threads_per_core=2` is a reasonable \n",
    "default. Just be careful if the number of threads is not specified it is possible that all workers try to access all \n",
    "cores at the same time which can lead to poor performance. So it is typically a good idea to monitor the CPU utilization\n",
    "with increasing number of workers. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c3146c1-8722-4b67-ab21-c250b8e7c9dd",
   "metadata": {},
   "source": [
    "Specific manycore CPU models like the Intel Xeon Phi processors provide a much higher hyper-threading ration and require\n",
    "a higher number of threads per core for optimal performance. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4976d45-0f4e-496c-8173-9631f512135b",
   "metadata": {},
   "source": [
    "### MPI Parallel Python Functions\n",
    "Beyond thread based parallelism, the message passing interface (MPI) is the de facto standard parallel execution in \n",
    "scientific computing and the [`mpi4py`](https://mpi4py.readthedocs.io) bindings to the MPI libraries are commonly used\n",
    "to parallelize existing workflows. The limitation of this approach is that it requires the whole code to adopt the MPI\n",
    "communication standards to coordinate the way how information is distributed. Just like the `pympipool.Executor` the \n",
    "[`mpi4py.futures.MPIPoolExecutor`](https://mpi4py.readthedocs.io/en/stable/mpi4py.futures.html#mpipoolexecutor) \n",
    "implements the [`concurrent.futures.Executor`](https://docs.python.org/3/library/concurrent.futures.html#module-concurrent.futures)\n",
    "interface. Still in this case eah python function submitted to the executor is still limited to serial execution. The\n",
    "novel approach of the `pympipool.Executor` is mixing these two types of parallelism. Individual functions can use\n",
    "the [`mpi4py`](https://mpi4py.readthedocs.io) library to handle the parallel execution within the context of this \n",
    "function while these functions can still me submitted to the `pympipool.Executor` just like any other function. The\n",
    "advantage of this approach is that the users can parallelize their workflows one function at the time. \n",
    "\n",
    "The following example illustrates the submission of a simple MPI parallel python function: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "cfa072a4-f88f-45b0-be94-a78f0edad513",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc(i):\n",
    "    from mpi4py import MPI\n",
    "    size = MPI.COMM_WORLD.Get_size()\n",
    "    rank = MPI.COMM_WORLD.Get_rank()\n",
    "    return i, size, rank"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "fd036b03-085d-4850-b11e-537c8fd476d5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(3, 2, 0), (3, 2, 1)]\n"
     ]
    }
   ],
   "source": [
    "with Executor(cores_per_worker=2) as exe:\n",
    "    fs = exe.submit(calc, 3)\n",
    "    print(fs.result())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4f97426-d8fb-42ef-98ca-135054bd39a7",
   "metadata": {},
   "source": [
    "The `calc()` function initializes the [`mpi4py`](https://mpi4py.readthedocs.io) library and gathers the size of the \n",
    "allocation and the rank of the current process within the MPI allocation. This function is then submitted to an \n",
    "`pympipool.Executor` which is initialized with a single worker with two cores `cores_per_worker=2`. So each function\n",
    "call is going to have access to two cores. \n",
    "\n",
    "Just like before the script can be called with any python interpreter even though it is using the [`mpi4py`](https://mpi4py.readthedocs.io)\n",
    "library in the background it is not necessary to execute the script with `mpiexec` or `mpirun`."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69dcfdcb-41db-4c3b-a1c5-07ff3be0c9a0",
   "metadata": {},
   "source": [
    "The response consists of a list of two tuples, one for each MPI parallel process, with the first entry of the tuple \n",
    "being the parameter `i=3`, followed by the number of MPI parallel processes assigned to the function call `cores_per_worker=2`\n",
    "and finally the index of the specific process `0` or `1`. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc41f241-663c-474e-ae1e-b2365389bc90",
   "metadata": {},
   "source": [
    "### GPU Assignment\n",
    "With the rise of machine learning applications, the use of GPUs for scientific application becomes more and more popular.\n",
    "Consequently, it is essential to have full control over the assignment of GPUs to specific python functions. In the \n",
    "following example the `tensorflow` library is used to identify the GPUs and return their configuration: "
   ]
  },
  {
   "cell_type": "raw",
   "id": "6ac9630b-4ab5-4f7f-bf55-812e8189da4f",
   "metadata": {},
   "source": [
    "import socket\n",
    "from tensorflow.python.client import device_lib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "998138f5-f0cb-47a7-ba36-7594b8ec41fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_available_gpus():\n",
    "    local_device_protos = device_lib.list_local_devices()\n",
    "    return [\n",
    "        (x.name, x.physical_device_desc, socket.gethostname()) \n",
    "        for x in local_device_protos if x.device_type == 'GPU'\n",
    "    ]"
   ]
  },
  {
   "cell_type": "raw",
   "id": "9d33af22-7b90-4ff7-a434-9c4cd9a930d5",
   "metadata": {},
   "source": [
    "with Executor(\n",
    "    max_workers=2, \n",
    "    gpus_per_worker=1, \n",
    ") as exe:\n",
    "    fs_1 = exe.submit(get_available_gpus)\n",
    "    fs_2 = exe.submit(get_available_gpus)\n",
    "    print(fs_1.result(), fs_2.result())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8dc7a989-908a-48a6-8d06-ac1e24173f5c",
   "metadata": {},
   "source": [
    "The additional parameter `gpus_per_worker=1` specifies that one GPU is assigned to each worker. This functionality \n",
    "requires `pympipool` to be connected to a resource manager like the [SLURM workload manager](https://www.schedmd.com)\n",
    "or preferably the [flux framework](https://flux-framework.org). The rest of the script follows the previous examples, \n",
    "as two functions are submitted and the results are printed. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1a17c6c-41ee-4595-913e-4af7272010a5",
   "metadata": {},
   "source": [
    "To clarify the execution of such an example on a high performance computing (HPC) cluster using the [SLURM workload manager](https://www.schedmd.com)\n",
    "the submission script is given below: "
   ]
  },
  {
   "cell_type": "raw",
   "id": "11ce332b-d2c1-4434-84c4-1e523e430848",
   "metadata": {},
   "source": [
    "#!/bin/bash\n",
    "#SBATCH --nodes=2\n",
    "#SBATCH --gpus-per-node=1\n",
    "#SBATCH --get-user-env=L\n",
    "\n",
    "python test_gpu.py"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14bf6228-db64-406b-b04f-4d23daaa836d",
   "metadata": {},
   "source": [
    "The important part is that for using the `pympipool.slurm.PySlurmExecutor` backend the script `test_gpu.py` does not \n",
    "need to be executed with `srun` but rather it is sufficient to just execute it with the python interpreter. `pympipool`\n",
    "internally calls `srun` to assign the individual resources to a given worker. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66e3be02-c11c-4053-9600-6bcfefefb127",
   "metadata": {},
   "source": [
    "For the more complex setup of running the [flux framework](https://flux-framework.org) as a secondary resource scheduler\n",
    "within the [SLURM workload manager](https://www.schedmd.com) it is essential that the resources are passed from the \n",
    "[SLURM workload manager](https://www.schedmd.com) to the [flux framework](https://flux-framework.org). This is achieved\n",
    "by calling `srun flux start` in the submission script: "
   ]
  },
  {
   "cell_type": "raw",
   "id": "aa0e2abf-7ab2-464f-a341-b93f91fbdd99",
   "metadata": {},
   "source": [
    "#!/bin/bash\n",
    "#SBATCH --nodes=2\n",
    "#SBATCH --gpus-per-node=1\n",
    "#SBATCH --get-user-env=L\n",
    "\n",
    "srun flux start python test_gpu.py"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c84fb7d-4285-4d73-8f1e-7cb88050eb85",
   "metadata": {},
   "source": [
    "As a result the GPUs available on the two compute nodes are reported: "
   ]
  },
  {
   "cell_type": "raw",
   "id": "a431e015-a309-49ac-9f10-756bda0177fc",
   "metadata": {},
   "source": [
    ">>> [('/device:GPU:0', 'device: 0, name: Tesla V100S-PCIE-32GB, pci bus id: 0000:84:00.0, compute capability: 7.0', 'cn138'),\n",
    ">>>  ('/device:GPU:0', 'device: 0, name: Tesla V100S-PCIE-32GB, pci bus id: 0000:84:00.0, compute capability: 7.0', 'cn139')]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70eb9a19-325e-4179-a196-4417e3f30e19",
   "metadata": {},
   "source": [
    "In this case each compute node `cn138` and `cn139` is equipped with one `Tesla V100S-PCIE-32GB`."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b554291-41ba-484d-b3da-a764bb286c4c",
   "metadata": {},
   "source": [
    "## External Executables\n",
    "While `pympipool` was initially designed for up-scaling python functions for HPC, the same functionality can be leveraged\n",
    "to up-scale any executable independent of the programming language it is developed in. This approach follows the design \n",
    "of the `flux.job.FluxExecutor` included in the [flux framework](https://flux-framework.org). In `pympipool` this approach\n",
    "is extended to support any kind of subprocess, so it is no longer limited to the [flux framework](https://flux-framework.org)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35e426c3-2e61-42f6-8c85-31dd288b7f51",
   "metadata": {},
   "source": [
    "### Subprocess\n",
    "Following the [`subprocess.check_output()`](https://docs.python.org/3/library/subprocess.html) interface of the standard\n",
    "python libraries, any kind of command can be submitted to the `pympipool.SubprocessExecutor`. The command can either be \n",
    "specified as a list `[\"echo\", \"test\"]` in which the first entry is typically the executable followed by the corresponding\n",
    "parameters or the command can be specified as a string `\"echo test\"` with the additional parameter `shell=True`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "91463388-789a-4749-b02f-71a6d76f9b96",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "False test\n",
      " True\n"
     ]
    }
   ],
   "source": [
    "from pympipool import SubprocessExecutor\n",
    "\n",
    "with SubprocessExecutor(max_workers=2) as exe:\n",
    "    future = exe.submit([\"echo\", \"test\"], universal_newlines=True)\n",
    "    print(future.done(), future.result(), future.done())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8c436db-fc60-45a8-8603-ff9a7e8439ca",
   "metadata": {},
   "source": [
    "In analogy to the previous examples the `SubprocessExecutor` class is directly imported from the `pympipool` module and \n",
    "the maximum number of workers is set to two `max_workers=2`. In contrast to the `pympipool.Executor` class no other\n",
    "settings to assign specific hardware to the command via the python interface are available in the `SubprocessExecutor` \n",
    "class. To specify the hardware requirements for the individual commands, the user has to manually assign the resources\n",
    "using the commands of the resource schedulers like `srun`, `flux run` or `mpiexec`.\n",
    "\n",
    "The `concurrent.futures.Future` object returned after submitting a command to the `pymipool.SubprocessExecutor` behaves\n",
    "just like any other future object. It provides a `done()` function to check if the execution completed as well as a \n",
    "`result()` function to return the output of the submitted command. \n",
    "\n",
    "In comparison to the `flux.job.FluxExecutor` included in the [flux framework](https://flux-framework.org) the \n",
    "`pymipool.SubprocessExecutor` differs in two ways. One the `pymipool.SubprocessExecutor` does not provide any option for\n",
    "resource assignment and two the `pymipool.SubprocessExecutor` returns the output of the command rather than just \n",
    "returning the exit status when calling `result()`. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "212cc7ed-b8df-447f-98df-e5390c839660",
   "metadata": {},
   "source": [
    "### Interactive Shell\n",
    "Beyond external executables which are called once with a set of input parameters and or input files and return one set\n",
    "of outputs, there are some executables which allow the user to interact with the executable during the execution. The \n",
    "challenge of interfacing a python process with such an interactive executable is to identify when the executable is ready\n",
    "to receive the next input. A very basis example for an interactive executable is a script which counts to the number \n",
    "input by the user. This can be written in python as `count.py`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "094f9afc-6fca-43c4-9794-51408ff5fc5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"count.py\", \"w\") as f:\n",
    "    f.writelines(\"\"\"\\\n",
    "def count(iterations):\n",
    "    for i in range(int(iterations)):\n",
    "        print(i)\n",
    "    print(\"done\")\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    while True:\n",
    "        user_input = input()\n",
    "        if \"shutdown\" in user_input:\n",
    "            break\n",
    "        else:\n",
    "            count(iterations=int(user_input))\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9eb17afc-ada6-4b75-b4e5-aba5a15e2512",
   "metadata": {},
   "source": [
    "This example is challenging in terms of interfacing it with a python process as the length of the output changes depending\n",
    "on the input. The first option that the `pympipool.ShellExecutor` provides is specifying the number of lines to read for\n",
    "each call submitted to the executable using the `lines_to_read` parameter. In comparison to the `SubprocessExecutor` \n",
    "defined above the `ShellExecutor` only supports the execution of a single executable at a time, correspondingly the input\n",
    "parameters for calling the executable are provided at the time of initialization of the `ShellExecutor` and the inputs \n",
    "are submitted using the `submit()` function:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "8ec6f955-8d40-42b0-a116-c5b538cc8e87",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "False 0\n",
      "1\n",
      "2\n",
      "3\n",
      "done\n",
      " True\n"
     ]
    }
   ],
   "source": [
    "from pympipool import ShellExecutor\n",
    "\n",
    "with ShellExecutor([\"python\", \"count.py\"], universal_newlines=True) as exe:\n",
    "    future_lines = exe.submit(string_input=\"4\", lines_to_read=5)\n",
    "    print(future_lines.done(), future_lines.result(), future_lines.done())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fcb6fdfc-d5c2-4008-91c1-3f935920cb7e",
   "metadata": {},
   "source": [
    "The response for a given set of input is again returned as `concurrent.futures.Future` object, this allows the user to\n",
    "execute other steps on the python side while waiting for the completion of the external executable. In this case the \n",
    "example counts the numbers from `0` to `3` and prints each of them in one line followed by `done` to notify the user its\n",
    "waiting for new inputs. This results in `n+1` lines of output for the input of `n`. Still predicting the number of lines\n",
    "for a given input can be challenging, so the `pympipool.ShellExecutor` class also provides the option to wait until a \n",
    "specific pattern is found in the output using the `stop_read_pattern`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "b048e987-2472-4481-87af-131ade1b1ce1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "False 0\n",
      "1\n",
      "2\n",
      "3\n",
      "done\n",
      " True\n"
     ]
    }
   ],
   "source": [
    "from pympipool import ShellExecutor\n",
    "\n",
    "with ShellExecutor([\"python\", \"count.py\"], universal_newlines=True) as exe:\n",
    "    future_pattern = exe.submit(string_input=\"4\", stop_read_pattern=\"done\")\n",
    "    print(future_pattern.done(), future_pattern.result(), future_pattern.done())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e59baad-fdd1-4895-8eed-efefedc91806",
   "metadata": {},
   "source": [
    "In this example the pattern simply searches for the string `done` in the output of the program and returns all the output\n",
    "gathered from the executable since the last input as the result of the `concurrent.futures.Future` object returned after\n",
    "the submission of the interactive command. "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
